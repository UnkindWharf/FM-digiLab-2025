#   FullMatrix Experimental Signal Classifier

This repository contains data preprocessing workflows for EMAT signal data and classifiers to detect the presence of flaws in physical pipes.

#   Data & Folder Structure

The folder structure is as follows:

```python
.
├── data  # Contains all data files
│   ├── raw # raw input .npy files
│   │   ├── pipe01 # all data for a pipe
│   │   │   ├── clean_<id>_<temp>.npy # clean signal 
│   │   │   └── defect_<id>_<temp>.npy # defect signal 
│   │   └── pipe02 # all data for another pipe
│   └── processed # preprocessed data and model files
│       ├── pipe01 # all data for a pipe
│       │   ├── data.csv # denoised data
│       │   ├── bss.csv # baseline subtracted data
│       │   ├── bss_svd.csv # baseline subtracted SVD data
│       │   ├── svd.pkl # SVD object
│       │   └── model.pkl # classifier object
│       └── pipe02 # all data for another pipe
├── fm_processor # library files
├── notebooks # jupyter
├── scripts
│   ├── preprocess.py # preprocessing script
│   ├── fit.py # model fitting script
│   └── inference.py # inference script
├── pyproject.toml # Poetry virtual environment file
└── README.md 
```

Pay particular attention to the `data` folder. 
- Data files in `data/raw` must follow this format:
    - All numpy `.npy` files
    - Of shape `(9, N)` where N is signal length
    - Row 0 contains timestamps, other rows contain nodal signals 
        - It's also OK to have shape `(2, N)` where second row contains sum of nodal signals
    - All starting `clean_` filenames treated as clean signals, everything else defect
    - `<id>` can be anything (including underscores)
    - `<temp>` must be 4 integers, denoting temperature with 2 decimal places. 
- All files in `data/processed` are generated by the preprocessing routines, and their names must not be changed.
- Raw data files in `data/raw/pipe01` or `data/raw/pipe02` can be in further subfolders. Add more pipe folders as needed.

#   Virtual Environment

The virtual environment is managed by [Poetry](https://python-poetry.org/). Install poetry via

```bash
pip install pipx
pipx install poetry
```

Then install the virtual environment using 

```bash
poetry install
```

This will create a `.lock` file and a virtual environment in the default poetry location

#   Preprocessing

After some raw data has been put into e.g. `data/raw/pipe01`, run the preprocessing routine with

```bash
poetry run python3 scripts/preprocess.py <path-to-raw-folder> <path-to-processed-folder>
```

For example: `poetry run python3 scripts/preprocess.py data/raw/pipe01 data/processed/pipe01` will read all raw data in `data/raw/pipe01` (and subfolders) and create the processed data files and SVD pickle in `data/processed/pipe01`. 

#   Model Fitting

After preprocessed data has been generated, you can fit a Support Vector Classifier (SVC) with:

```bash
poetry run python3 scripts/fit.py <path-to-processed-folder> <model_type>
```

For example: `poetry run python3 scripts/preprocess.py data/processed/pipe01 svc` will fit a SVC on data in `data/processed/pipe01` and write a model pickle to this same folder. Currently, the only supported model type is `svc`

#   Inference

This script will preprocess a raw test data file, load the model and SVD from the designated processed folder, and return the classification label for the sample. During inference, the routine uses a clean training data sample (in `data.csv`) with the closest temperature to the test sample for baseline subtraction. Do this with:

```bash
poetry run python3 scripts/inference.py <path-to-test-sample> <path-to-processed-folder>
```

For example: `poetry run python3 scripts/preprocess.py data/raw/test/defect_xxxx_1010.npy data/processed/pipe01 svc`

The script will print out a classification label (Defect = 1, Clean = 0)

#   TODO
- Allow batch inference for all files in folder
- Decouple temperature BSS logic from inference function
- Add Bernoulli classifier